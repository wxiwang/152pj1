else {log10(.)}
})
# Set categorical variables as factors
for(i in char_col) {
set(total, j=i, value = factor(total[[i]]))
}
# Splitting training and testing data
train <- total[1:32561,]
test <- total[32562:48842,]
# Standardizing numerical variables
num_col <- colnames(total)[sapply(total, is.numeric)]
for (col in num_col){
train[col] <- scale(train[col])
test[col] <- scale(test[col])
}
# Replace missing values with median
imp1 <- impute(obj = train, target = "target",classes = list(numeric = imputeMedian(),
factor = imputeMode()))
imp2 <- impute(obj = test, target = "target",classes = list(numeric = imputeMedian(),
factor = imputeMode()))
train <- imp1$data
test <- imp2$data
# split the data set into S samples
set.seed(141)
s <- 10
groups <- sample(seq_len(s), nrow(train), replace = TRUE)
dir.create("train/", showWarnings = FALSE)
for (i in seq_len(s)) {
write_csv(filter(train, groups == i), str_c("train/", i, ".csv"))
}
file_names <- file.path("train", list.files("train")) # list of file names under "train" dir
# define each_boot
each_boot <- function(i, data, j){
freqs <- rmultinom(1, nrow(train), rep(1, nrow(data)))
fit <- glm(target ~
age +
marital.status +
sex +
hours.per.week +
race +
education.num +
net.capital.gain,
data = data,
weights = freqs,
family = "binomial")
(fit$coefficients)[j]
}
r <- 8 # Sample r times for each subsample
each_subsample <- function(file_name, j){
subsample <- read.csv(file_name)
head(subsample)
seq_len(r) %>%
map_dbl(each_boot, data = subsample, j = j) %>%
quantile(c(0.025, 0.975))
}
# define jth_coef: non-parallel
jth_coef <- function(j){
file_names %>%
map(each_subsample, j = j) %>%
reduce(`+`) / s
}
# define jth_coef: parallel
jth_coef <- function(j) {
cl <- makeCluster(8)
clusterExport(cl, c("file_names",
"%>%",
"r",
"s",
"map",
"reduce",
"jth_coef",
"map_dbl",
"each_boot",
"train"))
coef_ci <- (parLapplyLB(cl, file_names, each_subsample, j=j) %>%
reduce(`+`)/s)
stopCluster(cl)
coef_ci
}
# 95% Confidence interval for the j-th coefficient
coef_names <- c("(Intercept)",
"age",
"marital.statusseparated",
"sexMale",
"hours.per.week",
"raceothers",
"net.capital.gain")
for(i in 1:length(coef_names)) {
print(coef_names[i])
print(jth_coef(i))
}
# split the data set into S samples
set.seed(141)
s <- 10
groups <- sample(seq_len(s), nrow(train), replace = TRUE)
dir.create("train/", showWarnings = FALSE)
for (i in seq_len(s)) {
write_csv(filter(train, groups == i), str_c("train/", i, ".csv"))
}
file_names <- file.path("train", list.files("train")) # list of file names under "train" dir
# split the data set into S samples
set.seed(141)
s <- 10
groups <- sample(seq_len(s), nrow(train), replace = TRUE)
dir.create("train/", showWarnings = FALSE)
for (i in seq_len(s)) {
write_csv(filter(train, groups == i), str_c("train/", i, ".csv"))
}
file_names <- file.path("train", list.files("train")) # list of file names under "train" dir
# 95% Confidence interval for the j-th coefficient
coef_names <- c("(Intercept)",
"age",
"marital.statusseparated",
"sexMale",
"hours.per.week",
"raceothers",
"net.capital.gain")
for(i in 1:length(coef_names)) {
print(coef_names[i])
print(jth_coef(i))
}
# split the data set into S samples
set.seed(141)
s <- 10
groups <- sample(seq_len(s), nrow(train), replace = TRUE)
dir.create("train/", showWarnings = FALSE)
for (i in seq_len(s)) {
write_csv(filter(train, groups == i), str_c("train/", i, ".csv"))
}
file_names <- file.path("train", list.files("train")) # list of file names under "train" dir
# split the data set into S samples
set.seed(141)
s <- 10
groups <- sample(seq_len(s), nrow(train), replace = TRUE)
dir.create("train/", showWarnings = FALSE)
for (i in seq_len(s)) {
write_csv(filter(train, groups == i), str_c("train/", i, ".csv"))
}
file_names <- file.path("train", list.files("train")) # list of file names under "train" dir
# define each_boot
each_boot <- function(i, data, j){
freqs <- rmultinom(1, nrow(train), rep(1, nrow(data)))
fit <- glm(target ~
age +
marital.status +
sex +
hours.per.week +
race +
education.num +
net.capital.gain,
data = data,
weights = freqs,
family = "binomial")
(fit$coefficients)[j]
}
r <- 8 # Sample r times for each subsample
each_subsample <- function(file_name, j){
subsample <- read.csv(file_name)
head(subsample)
seq_len(r) %>%
map_dbl(each_boot, data = subsample, j = j) %>%
quantile(c(0.025, 0.975))
}
# define jth_coef: non-parallel
jth_coef <- function(j){
file_names %>%
map(each_subsample, j = j) %>%
reduce(`+`) / s
}
# define jth_coef: parallel
jth_coef <- function(j) {
cl <- makeCluster(8)
clusterExport(cl, c("file_names",
"%>%",
"r",
"s",
"map",
"reduce",
"jth_coef",
"map_dbl",
"each_boot",
"train"))
coef_ci <- (parLapplyLB(cl, file_names, each_subsample, j=j) %>%
reduce(`+`)/s)
stopCluster(cl)
coef_ci
}
# 95% Confidence interval for the j-th coefficient
coef_names <- c("(Intercept)",
"age",
"marital.statusseparated",
"sexMale",
"hours.per.week",
"raceothers",
"net.capital.gain")
for(i in 1:length(coef_names)) {
print(coef_names[i])
print(jth_coef(i))
}
file_names
subsample <- read.csv(file_name)
subsample <- read.csv("train1.csv")
subsample <- read.csv("train/1.csv")
head(subsample)
getwd()
library(tidyverse)
library(data.table)
library(mlr)
library(parallel)
library(stringr)
library(psych)
library(cowplot)
setwd("/Users/acat/Documents/141c project")
# 95% Confidence interval for the j-th coefficient
coef_names <- c("(Intercept)",
"age",
"marital.statusseparated",
"sexMale",
"hours.per.week",
"raceothers",
"net.capital.gain")
for(i in 1:length(coef_names)) {
print(coef_names[i])
print(jth_coef(i))
}
sub1<-read.csv(train/1.csv)
fit<-glm(target ~
age +
marital.status +
sex +
hours.per.week +
race +
education.num +
net.capital.gain,
data = sub1,
weights = freqs,
family = "binomial")
sub1<-read.csv(train\1.csv)
sub1<-read.csv("train/1.csv")
fit<-glm(target ~
age +
marital.status +
sex +
hours.per.week +
race +
education.num +
net.capital.gain,
data = sub1,
weights = freqs,
family = "binomial")
fit<-glm(target ~
age +
marital.status +
sex +
hours.per.week +
race +
education.num +
net.capital.gain,
data = sub1,
family = "binomial")
fit
ls()
ls(all.names = TRUE)
y<-c(221,319,435,541,704,994,1301,1697,2247,2943,3680,4663,6411,9259,13789,19383)
x<-5:20
x
length(x)==length(y)
data<-data.frame(x,y)
fit<-lm(log(y)~x,data)
summary(fit)
plot(x,log(y))
plot(x,y)
fit<-lm(y~x,data)
summary(fit)
x<-c(71.585,71.608,71.493)
mean(x)
sd(x)
x<-c(15.303,200.098,44.020)
mean(x)
sd(x)
x<-c(20.748,16.050,16.265)
mean(x)
sd(x)
x<-c(153.498,49.059,16.655)
sd(x)
mean(x)
x<-c(16.418,28.832,16.716)
x<-c(16.418,28.832,16.716)
mean(x)
sd(x)
x<-c(25.871,55.169,235.391)
mean(x)
sd(x)
x<-c(23.773,15.764,15.821)
mean(x)
sd(x)
setwd("/Users/acat/CLionProjects/152pj1/projectData")
lambda1 <- read.table("lambda=0.1.txt",sep=",",header = TRUE)
lambda2 <- read.table("lambda=0.2.txt",sep=",",header = TRUE)
lambda4 <- read.table("lambda=0.4.txt",sep=",",header = TRUE)
lambda5 <- read.table("lambda=0.5.txt",sep=",",header = TRUE)
lambda6 <- read.table("lambda=0.6.txt",sep=",",header = TRUE)
lambda8 <- read.table("lambda=0.8.txt",sep=",",header = TRUE)
lambda9 <- read.table("lambda=0.9.txt",sep=",",header = TRUE)
seq_len(3)
seq_len(row(lambda1)-1)
row(lambda1)
length(lambda1)
nrow(lambda1)-1
(lambda1$time[nrow(lambda1)])
total.area = 0
for i in seq_len(nrow(lambda1)-1){
total.area = 0
for (i in seq_len(nrow(lambda1)-1)){
total_area += lambda1$queueLength[i]*(lambda1$time[i+1]-lambda1$time[i])
total.area = 0
for (i in seq_len(nrow(lambda1)-1)){
total.area = total.area + lambda1$queueLength[i]*(lambda1$time[i+1]-lambda1$time[i])
}
mean.queue.length = total.area/(lambda1$time[nrow(lambda1)])
mean.queue.length
total.area = 0
for (i in seq_len(nrow(lambda1)-1)){
total.area = total.area + lambda1$queueLength[i]*(lambda1$time[i+1]-lambda1$time[i])
}
mean.queue.length = total.area/(lambda1$time[nrow(lambda1)])
mean.queue.length
total.area1 = 0
for (i in seq_len(nrow(lambda1)-1)){
total.area1 = total.area1 + lambda1$queueLength[i]*(lambda1$time[i+1]-lambda1$time[i])
}
mean.queue.length1 = total.area1/(lambda1$time[nrow(lambda1)])
mean.queue.length1
total.area1 = 0
for (i in seq_len(nrow(lambda1)-1)){
total.area1 = total.area1 + lambda1$queueLength[i]*(lambda1$time[i+1]-lambda1$time[i])
}
mean.queue.length1 = total.area1/(lambda1$time[nrow(lambda1)])
mean.queue.length1
total.area2 = 0
for (i in seq_len(nrow(lambda1)-1)){
total.area2 = total.area2 + lambda1$queueLength[i]*(lambda1$time[i+1]-lambda1$time[i])
}
mean.queue.length2 = total.area2/(lambda1$time[nrow(lambda1)])
mean.queue.length2
total.area2 = 0
for (i in seq_len(nrow(lambda2)-1)){
total.area2 = total.area2 + lambda2$queueLength[i]*(lambda2$time[i+1]-lambda2$time[i])
}
mean.queue.length2 = total.area2/(lambda2$time[nrow(lambda2)])
mean.queue.length2
total.area3 = 0
for (i in seq_len(nrow(lambda3)-1)){
total.area3 = total.area3 + lambda3$queueLength[i]*(lambda3$time[i+1]-lambda3$time[i])
}
total.area4 = 0
for (i in seq_len(nrow(lambda4)-1)){
total.area4 = total.area4 + lambda4$queueLength[i]*(lambda4$time[i+1]-lambda4$time[i])
}
mean.queue.length4 = total.area4/(lambda4$time[nrow(lambda4)])
mean.queue.length4
total.area5 = 0
for (i in seq_len(nrow(lambda5)-1)){
total.area5 = total.area5 + lambda5$queueLength[i]*(lambda5$time[i+1]-lambda5$time[i])
}
mean.queue.length5 = total.area5/(lambda5$time[nrow(lambda5)])
mean.queue.length5
total.area6 = 0
for (i in seq_len(nrow(lambda6)-1)){
total.area6 = total.area6 + lambda6$queueLength[i]*(lambda6$time[i+1]-lambda6$time[i])
}
mean.queue.length6 = total.area6/(lambd61$time[nrow(lambda6)])
total.area6 = 0
for (i in seq_len(nrow(lambda6)-1)){
total.area6 = total.area6 + lambda6$queueLength[i]*(lambda6$time[i+1]-lambda6$time[i])
}
mean.queue.length6 = total.area6/(lambd6$time[nrow(lambda6)])
total.area6 = 0
for (i in seq_len(nrow(lambda6)-1)){
total.area6 = total.area6 + lambda6$queueLength[i]*(lambda6$time[i+1]-lambda6$time[i])
}
mean.queue.length6 = total.area6/(lambda6$time[nrow(lambda6)])
mean.queue.length6
library(tidyverse)
"lambda"+"0.1"+".txt"
paste("lambda=","0.1",".txt")
paste("lambda=","0.1",".txt",sep="")
lambda <- c("0.1","0.2","0.4","0.5","0.6","0.8","0.9")
lambda %>% map(function(x){
data <- read.table(paste("lambda=","0.1",".txt",sep=""))
total.area = 0
for (i in seq_len(nrow(data)-1)){
total.area = total.area + data$queueLength[i]*(data$time[i+1]-data$time[i])
}
mean.queue.length = total.area/(data$time[nrow(data)])
mean.queue.length
})
lambda <- c("0.1","0.2","0.4","0.5","0.6","0.8","0.9")
lambda %>% map(function(x){
data <- read.table(paste("lambda=",x,".txt",sep=""))
total.area = 0
for (i in seq_len(nrow(data)-1)){
total.area = total.area + data$queueLength[i]*(data$time[i+1]-data$time[i])
}
mean.queue.length = total.area/(data$time[nrow(data)])
mean.queue.length
})
x<-"0.1"
data <- read.table(paste("lambda=",x,".txt",sep=""))
head(data)
lambda <- c("0.1","0.2","0.4","0.5","0.6","0.8","0.9")
lambda %>% map(function(x){
data <- read.table(paste("lambda=",x,".txt",sep=""),sep=",",header = TRUE)
total.area = 0
for (i in seq_len(nrow(data)-1)){
total.area = total.area + data$queueLength[i]*(data$time[i+1]-data$time[i])
}
mean.queue.length = total.area/(data$time[nrow(data)])
mean.queue.length
})
lambda <- c("0.1","0.2","0.4","0.5","0.6","0.8","0.9")
queue.length.vector<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,".txt",sep=""),sep=",",header = TRUE)
total.area = 0
for (i in seq_len(nrow(data)-1)){
total.area = total.area + data$queueLength[i]*(data$time[i+1]-data$time[i])
}
mean.queue.length = total.area/(data$time[nrow(data)])
mean.queue.length
})
queue.length.vector
numeric.lambda <- c(0.1,0.2,0.4,0.5,0.6,0.8,0.9)
plot(numeric.lambda,queue.length.vector)
numeric.lambda <- c(0.1,0.2,0.4,0.5,0.6,0.8,0.9)
plot(numeric.lambda,queue.length.vector,xlab = "lambda",ylab = "queue length")
lambda <- c("0.1","0.2","0.4","0.5","0.6","0.8","0.9")
utilization.vector<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,".txt",sep=""),sep=",",header = TRUE)
busy.time = 0
for (i in seq_len(nrow(data)-1)){
if(data$queueLength[i]>0)busy.time = busy.time + (data$time[i+1]-data$time[i])
}
utilization = busy.time/(data$time[nrow(data)])
utilization
})
utilization.vector
plot(numeric.lambda,utilization.vector,xlab = "lambda",ylab = "utilization")
View(lambda1)
packet.loss.vector1<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=1",".txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector1
plot(numeric.lambda,packet.loss.vector1,xlab = "lambda",ylab = "total packet loss",main = "MAXBUFFER=1")
packet.loss.vector20<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=20",".txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector20<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=20",".txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector30<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=30",".txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector1<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=1",".txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector1
packet.loss.vector20<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=20.txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector1<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=1.txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector1
lambda <- c("0.2","0.4","0.5","0.6","0.8","0.9")
packet.loss.vector1<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=1.txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector1
packet.loss.vector20<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=20.txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector20
packet.loss.vector30<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=30",".txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector30
plot(numeric.lambda,packet.loss.vector1,xlab = "lambda",ylab = "total packet loss",main = "MAXBUFFER=1")
lambda <- c("0.1","0.2","0.4","0.5","0.6","0.8","0.9")
numeric.lambda <- c(0.2,0.4,0.5,0.6,0.8,0.9)
utilization.vector<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,".txt",sep=""),sep=",",header = TRUE)
busy.time = 0
for (i in seq_len(nrow(data)-1)){
if(data$queueLength[i]>0)busy.time = busy.time + (data$time[i+1]-data$time[i])
}
utilization = busy.time/(data$time[nrow(data)])
utilization
})
utilization.vector
plot(numeric.lambda,packet.loss.vector1,xlab = "lambda",ylab = "total packet loss",main = "MAXBUFFER=1")
plot(numeric.lambda,packet.loss.vector20,xlab = "lambda",ylab = "total packet loss",main = "MAXBUFFER=20")
plot(numeric.lambda,packet.loss.vector30,xlab = "lambda",ylab = "total packet loss",main = "MAXBUFFER=30")
