library(psych)
library(cowplot)
# Import data
setcol <- c("age",
"workclass",
"fnlwgt",
"education",
"education-num",
"marital-status",
"occupation",
"relationship",
"race","sex",
"capital-gain",
"capital-loss",
"hours-per-week",
"native-country",
"target")
train <- read.table("adult.data",
header = F,
sep = ",",
col.names = setcol,
na.strings = c(" ?"),
stringsAsFactors = F)
test <- read.table("adult.test",
header = F,
sep = ",",
col.names = setcol,
skip = 1,
na.strings = c(" ?"),
stringsAsFactors = F)
# Import data
setcol <- c("age",
"workclass",
"fnlwgt",
"education",
"education-num",
"marital-status",
"occupation",
"relationship",
"race","sex",
"capital-gain",
"capital-loss",
"hours-per-week",
"native-country",
"target")
train <- read.table("adult.data",
header = F,
sep = ",",
col.names = setcol,
na.strings = c(" ?"),
stringsAsFactors = F)
test <- read.table("adult.test",
header = F,
sep = ",",
col.names = setcol,
skip = 1,
na.strings = c(" ?"),
stringsAsFactors = F)
# summary statistics
summary(train)
# Age and Income
ggplot(train, aes(x=age, color=target, fill=target)) +
geom_density(alpha=0.7)
# Marital Status and Income
his1 <- ggplot(data=train, aes(x=marital.status))+
geom_bar() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Marital status of the individual", y = "Count")
his2 <- ggplot(data=train, aes(x = marital.status, fill = target)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
geom_bar(position="fill") +
labs(x = "Marital Status", y = "Proportion")
plot_grid(his1, his2, labels = "AUTO")
# Working Class and Income
ggplot(data=train, aes(x = workclass, fill = target)) +
geom_bar(position="fill") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Working Class", y = "Proportion")
# Gender and Income
gender.t <- select(train, target, sex)
ggplot(data = gender.t, aes(x=factor(1), stat="sex", fill = target)) +
geom_bar(position = "fill") +
coord_polar(theta="y") +
facet_grid(. ~ sex)
chisq.test(train$target, train$sex)
# Work Hours and Income
ggplot(train) +
geom_histogram(aes(x = hours.per.week, color = target, fill = target), alpha=.3, bins=10) +
geom_vline(aes(xintercept = mean(hours.per.week), colour=target), linetype="dashed", color="grey", size=1) +
scale_x_continuous("Hours per Week", seq(0, 100, 10)) +
labs(title = "Weekly Work Hours", y = "Density")
# Race and Income
his1 <- ggplot(data=train, aes(x=race))+
geom_bar() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Race", y = "Count")
his2 <- ggplot(data=train, aes(x = race, fill = target)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
geom_bar(position="fill") +
labs(x = "Race", y = "Proportion")
plot_grid(his1, his2, labels = "AUTO")
# Country and Income
ggplot(data = train, aes( x = native.country, color = target, fill = target)) +
geom_bar(position = "fill") +
coord_flip() +
labs(title = "Native Country", x = "Country of Origin", y = "Proportion")
# Final Weight and Income
ggplot(train, aes(x=fnlwgt, colour=target, fill=target)) +
geom_density(alpha=.3) +
geom_vline(aes(xintercept=mean(fnlwgt),  colour=target), linetype="dashed",color="grey", size=1) +
labs(x = "Final Weight", y = "Density")
ggplot(data=train, aes(x=relationship, fill = target)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
geom_bar(position="fill") +
labs(x = "Relationship", y = "Proportion")
# Education and Income 1
ggplot(data=train, aes(x = education, fill = target)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
geom_bar(position="fill") +
labs(x = "Education", y = "Proportion")
# Education and Income 2
ggplot(data=train, aes(x=education.num, fill = target)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
geom_bar(position="fill") +
labs(x = "Years of Education", y = "Proportion")
# Capital and Income
capital <- select(train, capital.gain, capital.loss, target)
capital$net.gain <- capital$capital.gain - capital$capital.loss
capital$log.net.gain <- log10(capital$net.gain)
ggplot(capital, aes(x = log.net.gain, colour = target, fill = target)) +
geom_density(alpha=.3) +
labs(title = "Captial and Income", x = "Log Net Gain", y = "Density")
# Delete dots within the test labels
test$target <- as.character(test$target)
test$target <- substr(test$target, start = 2, stop = nchar(test$target)-1)
# Combine train and test set
total <- rbind(train, test)
# Delete the blank space within the train labels
char_col <- colnames(total)[sapply(total, is.character)]
for (i in char_col) {
set(total, j = i,value = str_trim(total[[i]], side = "left"))
}
# Data engineering (combining multiple categories)
total$marital.status <- total$marital.status %>%
map_chr(~ {
if(. == "Married-AF-spouse") { "married" }
else if (. == "Married-civ-spouse") { "married" }
else { "separated" }
})
total$race <- total$race%>%
map_chr(~ {
if(. == "White") { "asian-white" }
else if (. == "Asian-Pac-Islander") { "asian-white" }
else { "others" }
})
total$net.capital.gain <- total$capital.gain - total$capital.loss
total$net.capital.gain <- total$net.capital.gain %>% map_dbl(~{
if (. <= 0) {0}
else {log10(.)}
})
# Set categorical variables as factors
for(i in char_col) {
set(total, j=i, value = factor(total[[i]]))
}
# Splitting training and testing data
train <- total[1:32561,]
test <- total[32562:48842,]
# Standardizing numerical variables
num_col <- colnames(total)[sapply(total, is.numeric)]
for (col in num_col){
train[col] <- scale(train[col])
test[col] <- scale(test[col])
}
# Replace missing values with median
imp1 <- impute(obj = train, target = "target",classes = list(numeric = imputeMedian(),
factor = imputeMode()))
imp2 <- impute(obj = test, target = "target",classes = list(numeric = imputeMedian(),
factor = imputeMode()))
train <- imp1$data
test <- imp2$data
# split the data set into S samples
set.seed(141)
s <- 10
groups <- sample(seq_len(s), nrow(train), replace = TRUE)
dir.create("train/", showWarnings = FALSE)
for (i in seq_len(s)) {
write_csv(filter(train, groups == i), str_c("train/", i, ".csv"))
}
file_names <- file.path("train", list.files("train")) # list of file names under "train" dir
# define each_boot
each_boot <- function(i, data, j){
freqs <- rmultinom(1, nrow(train), rep(1, nrow(data)))
fit <- glm(target ~
age +
marital.status +
sex +
hours.per.week +
race +
education.num +
net.capital.gain,
data = data,
weights = freqs,
family = "binomial")
(fit$coefficients)[j]
}
r <- 8 # Sample r times for each subsample
each_subsample <- function(file_name, j){
subsample <- read.csv(file_name)
head(subsample)
seq_len(r) %>%
map_dbl(each_boot, data = subsample, j = j) %>%
quantile(c(0.025, 0.975))
}
# define jth_coef: non-parallel
jth_coef <- function(j){
file_names %>%
map(each_subsample, j = j) %>%
reduce(`+`) / s
}
# define jth_coef: parallel
jth_coef <- function(j) {
cl <- makeCluster(8)
clusterExport(cl, c("file_names",
"%>%",
"r",
"s",
"map",
"reduce",
"jth_coef",
"map_dbl",
"each_boot",
"train"))
coef_ci <- (parLapplyLB(cl, file_names, each_subsample, j=j) %>%
reduce(`+`)/s)
stopCluster(cl)
coef_ci
}
# 95% Confidence interval for the j-th coefficient
coef_names <- c("(Intercept)",
"age",
"marital.statusseparated",
"sexMale",
"hours.per.week",
"raceothers",
"net.capital.gain")
for(i in 1:length(coef_names)) {
print(coef_names[i])
print(jth_coef(i))
}
# split the data set into S samples
set.seed(141)
s <- 10
groups <- sample(seq_len(s), nrow(train), replace = TRUE)
dir.create("train/", showWarnings = FALSE)
for (i in seq_len(s)) {
write_csv(filter(train, groups == i), str_c("train/", i, ".csv"))
}
file_names <- file.path("train", list.files("train")) # list of file names under "train" dir
# split the data set into S samples
set.seed(141)
s <- 10
groups <- sample(seq_len(s), nrow(train), replace = TRUE)
dir.create("train/", showWarnings = FALSE)
for (i in seq_len(s)) {
write_csv(filter(train, groups == i), str_c("train/", i, ".csv"))
}
file_names <- file.path("train", list.files("train")) # list of file names under "train" dir
# 95% Confidence interval for the j-th coefficient
coef_names <- c("(Intercept)",
"age",
"marital.statusseparated",
"sexMale",
"hours.per.week",
"raceothers",
"net.capital.gain")
for(i in 1:length(coef_names)) {
print(coef_names[i])
print(jth_coef(i))
}
# split the data set into S samples
set.seed(141)
s <- 10
groups <- sample(seq_len(s), nrow(train), replace = TRUE)
dir.create("train/", showWarnings = FALSE)
for (i in seq_len(s)) {
write_csv(filter(train, groups == i), str_c("train/", i, ".csv"))
}
file_names <- file.path("train", list.files("train")) # list of file names under "train" dir
# split the data set into S samples
set.seed(141)
s <- 10
groups <- sample(seq_len(s), nrow(train), replace = TRUE)
dir.create("train/", showWarnings = FALSE)
for (i in seq_len(s)) {
write_csv(filter(train, groups == i), str_c("train/", i, ".csv"))
}
file_names <- file.path("train", list.files("train")) # list of file names under "train" dir
# define each_boot
each_boot <- function(i, data, j){
freqs <- rmultinom(1, nrow(train), rep(1, nrow(data)))
fit <- glm(target ~
age +
marital.status +
sex +
hours.per.week +
race +
education.num +
net.capital.gain,
data = data,
weights = freqs,
family = "binomial")
(fit$coefficients)[j]
}
r <- 8 # Sample r times for each subsample
each_subsample <- function(file_name, j){
subsample <- read.csv(file_name)
head(subsample)
seq_len(r) %>%
map_dbl(each_boot, data = subsample, j = j) %>%
quantile(c(0.025, 0.975))
}
# define jth_coef: non-parallel
jth_coef <- function(j){
file_names %>%
map(each_subsample, j = j) %>%
reduce(`+`) / s
}
# define jth_coef: parallel
jth_coef <- function(j) {
cl <- makeCluster(8)
clusterExport(cl, c("file_names",
"%>%",
"r",
"s",
"map",
"reduce",
"jth_coef",
"map_dbl",
"each_boot",
"train"))
coef_ci <- (parLapplyLB(cl, file_names, each_subsample, j=j) %>%
reduce(`+`)/s)
stopCluster(cl)
coef_ci
}
# 95% Confidence interval for the j-th coefficient
coef_names <- c("(Intercept)",
"age",
"marital.statusseparated",
"sexMale",
"hours.per.week",
"raceothers",
"net.capital.gain")
for(i in 1:length(coef_names)) {
print(coef_names[i])
print(jth_coef(i))
}
file_names
subsample <- read.csv(file_name)
subsample <- read.csv("train1.csv")
subsample <- read.csv("train/1.csv")
head(subsample)
getwd()
library(tidyverse)
library(data.table)
library(mlr)
library(parallel)
library(stringr)
library(psych)
library(cowplot)
setwd("/Users/acat/Documents/141c project")
# 95% Confidence interval for the j-th coefficient
coef_names <- c("(Intercept)",
"age",
"marital.statusseparated",
"sexMale",
"hours.per.week",
"raceothers",
"net.capital.gain")
for(i in 1:length(coef_names)) {
print(coef_names[i])
print(jth_coef(i))
}
sub1<-read.csv(train/1.csv)
fit<-glm(target ~
age +
marital.status +
sex +
hours.per.week +
race +
education.num +
net.capital.gain,
data = sub1,
weights = freqs,
family = "binomial")
sub1<-read.csv(train\1.csv)
sub1<-read.csv("train/1.csv")
fit<-glm(target ~
age +
marital.status +
sex +
hours.per.week +
race +
education.num +
net.capital.gain,
data = sub1,
weights = freqs,
family = "binomial")
fit<-glm(target ~
age +
marital.status +
sex +
hours.per.week +
race +
education.num +
net.capital.gain,
data = sub1,
family = "binomial")
fit
ls()
ls(all.names = TRUE)
y<-c(221,319,435,541,704,994,1301,1697,2247,2943,3680,4663,6411,9259,13789,19383)
x<-5:20
x
length(x)==length(y)
data<-data.frame(x,y)
fit<-lm(log(y)~x,data)
summary(fit)
plot(x,log(y))
plot(x,y)
fit<-lm(y~x,data)
summary(fit)
x<-c(71.585,71.608,71.493)
mean(x)
sd(x)
x<-c(15.303,200.098,44.020)
mean(x)
sd(x)
x<-c(20.748,16.050,16.265)
mean(x)
sd(x)
x<-c(153.498,49.059,16.655)
sd(x)
mean(x)
x<-c(16.418,28.832,16.716)
x<-c(16.418,28.832,16.716)
mean(x)
sd(x)
x<-c(25.871,55.169,235.391)
mean(x)
sd(x)
x<-c(23.773,15.764,15.821)
mean(x)
sd(x)
library(tidyverse)
setwd("/Users/acat/CLionProjects/152pj1/projectData")
lambda <- c("0.1","0.2","0.4","0.5","0.6","0.8","0.9")
queue.length.vector<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,".txt",sep=""),sep=",",header = TRUE)
total.area = 0
for (i in seq_len(nrow(data)-1)){
total.area = total.area + data$queueLength[i]*(data$time[i+1]-data$time[i])
}
mean.queue.length = total.area/(data$time[nrow(data)])
mean.queue.length
})
queue.length.vector
numeric.lambda <- c(0.1,0.2,0.4,0.5,0.6,0.8,0.9)
plot(numeric.lambda,queue.length.vector,xlab = "lambda",ylab = "queue length")
utilization.vector<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,".txt",sep=""),sep=",",header = TRUE)
busy.time = 0
for (i in seq_len(nrow(data)-1)){
if(data$queueLength[i]>0)busy.time = busy.time + (data$time[i+1]-data$time[i])
}
utilization = busy.time/(data$time[nrow(data)])
utilization
})
utilization.vector
plot(numeric.lambda,utilization.vector,xlab = "lambda",ylab = "utilization")
lambda <- c("0.2","0.4","0.5","0.6","0.8","0.9")
plot(numeric.lambda,utilization.vector,xlab = "lambda",ylab = "utilization",type="l")
lambda <- c("0.2","0.4","0.5","0.6","0.8","0.9")
numeric.lambda <- c(0.2,0.4,0.5,0.6,0.8,0.9)
packet.loss.vector1<-lambda %>% map_dbl(function(x){
data <- read.table(paste("lambda=",x,",MAXBUFFER=1.txt",sep=""),sep=",",header = TRUE)
data$totalPacketLoss[nrow(data)]
})
packet.loss.vector1
fit<-lm(queue.length.vector~poly(numeric.lambda,3))
numeric.lambda <- c(0.1,0.2,0.4,0.5,0.6,0.8,0.9)
fit<-lm(queue.length.vector~poly(numeric.lambda,3))
plot(fit)
myPredict <- predict(fit)
ix <- sort(numeric.lambda,index.return=T)$ix
lines(numeric.lambda[ix], myPredict[ix], col=2, lwd=2 )
lines(numeric.lambda[ix], myPredict[ix], col=2, lwd=2 )
plot(numeric.lambda,queue.length.vector,xlab = "lambda",ylab = "queue length")
lines(numeric.lambda[ix], myPredict[ix], col=2, lwd=2 )
x <- with(seq(min(numeric.lambda), max(numeric.lambda), length.out=2000))
data<-data.frame(numeric.lambda,queue.length.vector)
data
x <- with(data,seq(min(numeric.lambda), max(numeric.lambda), length.out=2000))
y <- predict(fit, newdata = data.frame(numeric.lambda = x))
plot(queue.length.vector ~ numeric.lambda, data = data)
lines(x, y, col = "red")
fit
fit<-lm(queue.length.vector~poly(numeric.lambda,2),data)
y <- predict(fit, newdata = data.frame(numeric.lambda = x))
plot(queue.length.vector ~ numeric.lambda, data = data)
lines(x, y, col = "red")
summary(fit)
